title,authors,year,prior_user_research,"If study was used, type of study used",,audiences,stakeholders_mentioned,stakeholders_involved,"What is the precise context of use of the tool as presented by authors
",tool_evaluation,degree_automation,tool_integration,tool_description
Data Statements | Tech Policy Lab,"McMillan-Major, Angelina; Bender, Emily M.",2023,No,"This paper is about Data Statements version 3

This is debatable. Data Statements version 2 was developed using a workshop with NLP practitioners. Data version 3 with addressess community dataset development, was not developed with communities per se.",,"dataset creators, dataset users",Yes,No,"linguistic contexts primarily but could be broader
""While first developed with language data types, data statements could be produced for a wide range of data types with adjustments to the schema to account for the unique characteristics of the specific data type.""",No,Manual,No,toolkit
The Dataset Nutrition Label: A Framework To Drive Higher Data Quality Standards,"Holland, Sarah; Hosny, Ahmed; Newman, Sarah; Joseph, Joshua; Chmielinski, Kasia",2018,Yes,"I am saying yes even though the study was not oritented towards understanding particular needs or practices in regards to documentation specifically. 

""We conducted an anonymous online survey (Figure 2), the results of which further lend credence to this problem. Although many (47%) respondents report conducting some form of data analysis prior to model development, most (74%) indicate that their organizations do not have explicit best practices for such analysis. Fifty-nine percent of respondents reported relying primarily on experience and self-directed learning (through online tutorials, blogs, academic papers, stack overflow, and online data competitions) to inform their data analysis methods and practices. This survey indicates that despite limited current standards, there is widespread interest to improve data analysis practices and make them accessible and standardize""

However, the design of the tool was guided by their own understanding of the lit 

""To inform the development of our prototype and concept, we surveyed the literature for labeling efforts. """,,dataset creators,Yes,Yes,"Their intention overall is to be context-independent: dataset analysis, preprocessing phase of model development, dataset selection, data collection, across backgrounds and domains. They recognize the challenges of being so context-independent (last quote). 

""The modules are stand-alone, allowing for greater flexibility as arrangements of different modules can be used for different types of datasets. This format also caters to a wide range of requirements and information available for a specific dataset. During label generation and subsequent updates, it also accommodates data specialists of different backgrounds and technical skill levels.""


""We hypothesize that the concept of a “nutrition label” for datasets is an effective means to provide a scalable and efficient tool to improve the process of dataset interrogation and analysis prior to and during model development. In supporting our hypothesis, we created a prototype, the Dataset Nutrition Label (the Label). Three goals drive this work. First, to inform and improve data specialists’ selection and interrogation of datasets and to prompt critical analysis. Consequently, data specialists are the primary intended audience. Second, to gain traction as a practical, readily deployable tool, we prioritize efficiency and flexibility. To that end, we do not suggest one specific approach to the Label, or charge one specific community with creating the Label. Rather, our prototype is modular, and the underlying framework is one that anyone can use. Lastly, we leverage probabilistic computing tools to surface potential corollaries, anomalies, and proxies. This is particularly beneficial because resolving these issues requires excess development time, and can lead to undesired correlations in trained model""

""The Label offers many benefits. Overall, it prompts critical questions and interrogation in the preprocessing phase of model development. It also expedites decision making, which saves time in the overall model development phase without sacrificing the quality or thoroughness of the data interrogation itself, perhaps encouraging better practices at scale. These benefits apply across the spectrum of data specialists’ skill and experience, but are particularly useful for those new to the field or less attuned to concerns around bias and algorithmic accountability""

""For data specialists, the Label will drive more robust data analysis practices, provide an efficient way to select the best dataset for their purposes, and increase the overall quality of AI models as a result of more robust training datasets and the ability to check for issues at the time of model development. For those building and publishing datasets, the Label creates an expectation of explanation, which will drive better data collection practices.""


""There are challenges to our approach. The extensive variety of datasets used to build models raises important questions around whether the Label can generalize across data and dataset type, size, composition, and in different domains, and furthermore, whether a data specialist or domain expert will need to be involved in the creation of a Label across these different datasets. This could arise in an instance where important semantic information is atypically labeled and would be challenging to interpret automatically, such as if the field for zip code in a dataset had a custom field for “geographic area.” A data specialist or domain expert may also be required when building a Label for sensitive or proprietary data, which may be accessible only to those who built the dataset and not accessible to the public.""
",No,Hybrid,No,framework
Towards accountability for machine learning datasets: Practices from software engineering and infrastructure,"Hutchinson, Ben; Smart, Andrew; Hanna, Alex; Denton, Emily; Greer, Christina; Kjartansson, Oddur; Barnes, Parker; Mitchell, Margaret",2021,No,,,dataset creators,Yes,No,"Artificial Ingeligence, 
Machine Learning datasets
Datasets lifecycle

uccessful im- plementation of our proposed frameworks depends critically on clearly formulated development processes, with discrete and in- terconnected stages. Owners charged with responsibility for each stage must work by consulting appropriate experts and produce detailed accounts of what happens during each stage, and why. The form of these accounts (requirements specifications, design docu- ments, testing reports, etc.) actively work to improve the quality, reliability and validity of the data itsel

Data poisoning may have oc- curred, labeling guidelines may have been misconstrued, or the phenomena in question may quite simply change. Affordances for manual edits and batch updates need to be in place (with appropri- ate access controls), and all such actions need to be scrupulously logged. Making these logs human-readable and searchable is an important step in dataset maintenance accountability.",No,Manual,No,framework
"Understanding machine learning practitioners' data documentation perceptions, needs, challenges, and desiderata","Heger, Amy K.; Marquis, Liz B.; Vorvoreanu, Mihaela; Wallach, Hanna; Wortman Vaughan, Jennifer",2022,,This is a n empirical study of existing dataset practices,,,No,No,,,,,
A generative benchmark creation framework for detecting common data table versions,"Fox, Daniel C.; Khatiwada, Aamod; Shraga, Roee",2024,No,,,dataset creators,No,No,"No precise context is described, there are only some broad suggestions such as 

""Enterprise and government organizations store massive numbers of datasets (tables) in centralized storage such as data lakes [9]."" and

""Data creators generally update existing datasets and upload them as new datasets to data repositories without proper documentation. Identifying such versions helps in data management, data governance, and making better decisions using data.""",No,Automated,No,framework
DataDoc analyzer: a tool for analyzing the documentation of scientific datasets,"Giner-Miguelez, Joan; Gómez, Abel; Cabot, Jordi",2023,No,,,"dataset creators, dataset users",No,No,"machine learning datasets

""empirical studies on the overall quality of the
datasets used in the ML field""

""creation of datasets documentation""",No,Automated,No,app
Datasheets for datasets,"Gebru, Timnit; Morgenstern, Jamie; Vecchione, Briana; Vaughan, Jennifer Wortman; Wallach, Hanna; III, Hal Daumé; Crawford, Kate",2021,No,"I am saying no to the previous queston because they did not conduct a user study per se but did include users and experts in iterating on the final product (the questions)

""we drew on our knowledge of dataset char- acteristics, unintentional misuse, unwanted societal biases, and other issues to produce an initial set of questions designed to elicit informa- tion about these topics. We then “test- ed” these questions by creating ex- ample datasheets for two widely used datasets: Labeled Faces in the Wild16 and Pang and Lee’s polarity dataset.22 We chose these datasets in large part because their creators provided ex- emplary documentation, allowing us to easily find the answers to many of the questions. While creating these example datasheets, we found gaps in the questions, as well as redundan- cies and lack of clarity. We therefore refined the questions and distributed them to product teams in two major U.S.-based technology companies, in some cases helping teams to create datasheets for their datasets and ob- serving where the questions did not achieve their intended objectives. Contemporaneously, we circulated an initial draft of this article to col- leagues through social media and on arXiv (draft posted Mar. 23, 2018). Via these channels we received extensive comments from dozens of research- ers, practitioners, and policy makers. We also worked with a team of lawyers to review the questions from a legal perspective. We incorporated this feedback to yield the questions and workflow pro- vided in the next section: We added and removed questions, refined the content of the questions, and reor- dered the questions to better match the key stages of the dataset life cycle. Based on our experiences with prod- uct teams, we reworded the questions to discourage yes/no answers, added a section on “Uses,” and deleted a sec- tion on “Legal and Ethical Consider- ations.” We found that product teams were more likely to answer questions about legal and ethical consider- ations if they were integrated into sec- tions about the relevant stages of the dataset lifecycle rather than grouped together. Finally, following feedback from the team of lawyers, we removed questions that explicitly asked about compliance with regulations, and in- troduced factual questions intended to elicit relevant information about compliance without requiring dataset creators to make legal judgments.""",,"dataset creators, dataset users",No,Yes,"The machine learning community

Research contexts: ""The following questions are primarily intended to encourage dataset creators to clearly articulate their reasons for creating the dataset and to promote transparency about funding interests. The latter may be particularly relevant for datasets created for research purposes.""

Industrial, team-based contexts: ""We therefore refined the questions and distributed them to product teams in two major U.S.-based technology companies, in some cases helping teams to create datasheets for their datasets and ob- serving where the questions did not achieve their intended objectives""

Diverse and quite flexible/varied contexts 

""Beyond these two key stakeholder groups, datasheets for datasets may be valuable to policy makers, con- sumer advocates, investigative jour- nalists, individuals whose data is included in datasets, and individu- als who may be impacted by models"", 

""Although we provide a set of ques- tions designed to elicit the informa- tion a datasheet for a dataset might contain, these questions are not in- tended to be prescriptive. Indeed, we expect that datasheets will neces- sarily vary depending on factors such as the domain or existing organiza- tional infrastructure and workflows. For example, some the questions are appropriate for academic research- ers publicly releasing datasets for the purpose of enabling future research, but less relevant for product""

""Contemporaneously, we circulated an initial draft of this article to col- leagues through social media and on arXiv (draft posted Mar. 23, 2018). Via these channels we received extensive comments from dozens of research- ers, practitioners, and policy makers"")",Yes,Manual,Yes,datasheet
CrowdWorkSheets: Accounting for individual and collective identities underlying crowdsourced dataset annotation,"Dı́az, Mark; Kivlichan, Ian; Rosen, Rachel; Baker, Dylan; Amironesei, Razvan; Prabhakaran, Vinodkumar; Denton, Emily",2022,No,,,dataset creators,No,No,"crowdsourced data annotation pipeline of machine learning datasets

""the challenges and decision points in- herent to crowdsourced annotation of machine learning datasets and propose a framework, CrowdWorkSheets, for reflecting on data- set annotation decisions, and documenting them in a standardized manner."" 

""CrowdWorkSheets, for dataset developers to fa- cilitate transparent documentation of key decisions points at var- ious stages of the data annotation pipeline: task formulation, se- lection of annotators, platform and infrastructure choices, dataset analysis and evaluation, and dataset release and maintenance.""",No,Manual,No,framework
DescribeML: a tool for describing machine learning datasets,"Giner-Miguelez, Joan; Gómez, Abel; Cabot, Jordi",2022,No,,,dataset creators,No,No,machine learning datasets,No,Hybrid,No,app
Goods: Organizing google's datasets,"Halevy, Alon; Korn, Flip; Noy, Natalya F.; Olston, Christopher; Polyzotis, Neoklis; Roy, Sudip; Whang, Steven Euijong",2016,No,"I am saying no because they do not priovide methodological details of how the study was conducted and are rather vague in describing the involvment of users in the process. However, they do mention something to this regard: 

""As we were developing Goods, we had several meetings with teams inside Google to discuss their pain points in dataset manage- ment. We realized very quickly the need for a holistic suite of data- management tools beyond search, including dashboards to monitor dataset health, automated dataset testing, and tools to understand differences among datasets.""",,"dataset creators, dataset users, dataset auditors",No,Yes,"It is very specific: enterprises with teams using diverse ways to produce datasets with no centralized system for storing and querying them. However the tool starts from the task, not from the context itself. 

""Enterprises increasingly rely on structured datasets to run their businesses. These datasets take a variety of forms, such as structured files, databases, spreadsheets, or even services that provide access to the data. The datasets often reside in di erent storage systems, may vary in their formats, may change every day. In this paper, we present Goods, a project to rethink how we organize structured datasets at scale, in a setting where teams use diverse and often idiosyncratic ways to produce the datasets and where there is no centralized system for storing and querying them.""

Another aspect of the context is that it can be distributed across geographical locations

""The engineers on the team may be distributed acros  the globe and they maintain several pipelines that add annotations to di erent text corpora. Each pipeline can have multiple stages that add annotations based on various techniques including phrase chunking, part-of-speech tagging, and co-reference resolution. Other teams can consume the datasets that the NLU team generates, and the NLU team’s pipelines may consume datasets from other teams.""",No,Hybrid,Yes,app
A domain-specific language for describing machine learning datasets,"Giner-Miguelez, Joan; Gómez, Abel; Cabot, Jordi",2023,No,,,dataset creators,No,No,"ML projects
ML research",Yes,Manual,No,app
Dataset construction challenges for digital forensics,"Horsman, Graeme; Lyle, James R.",2021,No,,,"dataset creators, dataset users",No,No,The creation and evaluation of datasets for datset forensic,No,Manual,Yes,
A Standardized Machine-readable Dataset Documentation Format for Responsible AI,"Jain, Nitisha; Akhtar, Mubashara; Giner-Miguelez, Joan; Shinde, Rajat; Vanschoren, Joaquin; Vogler, Steffen; Goswami, Sujata; Rao, Yuhan; Santos, Tim; Oala, Luis; Karamousadakis, Michalis; Maskey, Manil; Marcenac, Pierre; Conforti, Costanza; Kuchnik, Michael; Aroyo, Lora; Benjelloun, Omar; Simperl, Elena",2024,Yes,"An iterative vocabulary engineering process using participatory and codesign activities with experts, and including a participatory evaluation of the product. 

-------
This section presents the details of the vocabulary design and engineering process for Croissant-RAI format. The entire process has been led by commu- nity projects involving experts from various back- grounds, referred to as stakeholders below. The dif- ferent aspects of Croissant-RAI were meticulously defined using a comprehensive vocabulary engineer- ing process which was focused on iterative and par- ticipatory co-design activities

rom various domains and levels of expertise. Through several brainstorming sessions, stake- holders identified and prioritized the attributes for the Croissant-RAI format. This collaborative approach ensured that the identified use cases were comprehensive, relevant, and aligned with the overarching goals of promoting data standardization and responsible AI practices.

Scope Definition. Through participatory co- design activities, stakeholders formulated com- petency questions to that defined the scope and requirements of the Croissant-RAI vocabulary. These questions reflected diverse perspectives and priorities, acting as guiding principles. They helped identify the key features and function- alities necessary to meet the objectives of the Croissant-RAI vocabulary.

Conceptualization of RAI extension and Implementation. Building on insights from co-design activities discuss above, the conceptual framework for the Croissant-RAI vocabulary was defined on top of Croissant. Through col- laborative modeling sessions, concept mapping exercises, and scenario-based discussions, we en- sured that the Croissant-RAI vocabulary aligned with use cases, stakeholder priorities and did not overlap or contradiction with the Croissant format. Moreover, in biweekly sprint cycles a conceptual model of the Croissant-RAI vocabu- lary as developed. This facilitated an integration of Croissant-RAI with Croissant and ensured compatibility with existing functionalities",,,No,Yes,"AI -  data standardization and responsible AI practices for the data life cycle, data labelling, data participation, AI safety and fairness, and regulatory compliance. 

--------

Through several brainstorming sessions, stake- holders identified and prioritized the attributes for the Croissant-RAI format. This collaborative approach ensured that the identified use cases were comprehensive, relevant, and aligned with the overarching goals of promoting data standardization and responsible AI practices.

The initial use cases are centered on documenting
the data life cycle, characterizing in-depth data
labeling and data participatory processes, and providing
critical information for AI safety and fairness
assessments and regulatory compliance checks

The entire process has been led by community
projects involving experts from various backgrounds,
referred to as stakeholders below",Yes,Manual,No,markup format
Data-envelopes for cultural heritage: Going beyond datasheets,"Luthra, Mrinalini; Eskevich, Maria",2024,No,,,dataset creators,Yes,No,,No,Manual,No,
Language Dataset Documentation Design: Learning from Deaf and Indigenous Communities,"McMillan-Major, Angelina Yvonne",2023,Yes,"workshop with NLP practitioners

""to achieve these goals, we first conducted a workshop  with NLP practitioners in order to identify gaps and limitations of the toolkit as well as to develop best practices for writing data statements, yielding an interim improved toolkit. Then we conducted an analytic comparison between the interim toolkit and another documentation toolkit, datasheets for datasets. Based on these two integrated processes, we presented our revised Version 2 schema and best practices in a guide for writing data statements. Our findings more generally provide integrated processes for co-evolving both  technology and practice to address ethical concerns within situated technical communities""

Ths paper is about C3DAR, not Data Statements",,"dataset creators, dataset users",Yes,Yes,collaborative partnerships between communities and researchers working to develop language datasets,No,Manual,No,toolkit
Datasheets for AI and medical datasets (DAIMS): a data validation and documentation framework before machine learning analysis in medical research,"Marandi, Ramtin Zargari; Frahm, Anne Svane; Milojevic, Maja",2025,No,,,"dataset creators, data experts",No,No,"Even though the context is the medical field, there are many moments where authors try to make the case that the context can be much broader, that the tool is flexible enough for other uses that expand the context (e.g., various medical AI applications, not even limited to ML or medicine)


------
Use of ML in the medical field covering all aspects of the dataset lifecycle
guidelines for dataset maintenance, including versioning, mechanisms for updates, and clear attributions for interdisciplinary collaboration. 

However, it lacked domain-specific guidance critical for clinical and medical datasets, such as considerations for patient confidentiality. The current framework, DAIMS, addresses these gaps by incorporating domain-specific terminology, introducing a detailed checklist for data cleaning and standardization in medical data, and emphasizing subpopulation analysis and outcome variables. It also adds comprehensive sections on ethical review processes, data protection impact analyses, and mechanisms for dataset maintenance and updates, in line with medical research needs. These improvements make the framework more practical for documenting datasets in medical contexts, while still retaining its original focus on transparency and reproducibility.

The flowchart is designed to be adaptable across various medical AI applications, promoting a standardized yet flexible framework for model selection and development.


It also can serve as a documentation reference and framework for data versioning and warehousing where researchers can make informed decisions about the version of the dataset needed for a new study.

DAIMS is also formulated to cover a broad set of research applications and that means it can be applied to any relevant research area and is not limited to ML or medical research only. The data validation and documentation framework can be utilized across diverse research and application scenarios. A key use case is reporting detailed dataset information as part of research publication, such as in Paetzold et al.28. DAIMS also supports open science initiatives by facilitating dataset sharing and can serve as a tool for grant proposals or regulatory submissions.",No,Hybrid,No,framework
Datasheets for Energy Datasets: An Ethically-Minded Approach to Documentation,"Heintz, Ilana",2023,No,"This a paper about how documentation is being used (authors analyze energy-related public datasets to analyze the documentation) and then derive questions that the documentation framework could add for attending to the energy domain. I am marking it in red because there is no proposal of a tool as such, there are a group of questions (three I think) that the authors suggest should be considered for datasheets for energy. ",,dataset creators,No,No,"datasets in data-driven energy research
the collection, analysis, and distribution of datasets.
renewable energy development and other areas of energy research.
ethical AI in the energy domain",No,Manual,No,datasheet
Tackling Documentation Debt: A Survey on Algorithmic Fairness Datasets,"Fabris, Alessandro; Messina, Stefano; Silvello, Gianmaria; Susto, Gian Antonio",2022,No,"""Data briefs were drafted by the first author and reviewed by the remaining authors.""",,data curators,No,No,"fair ML, such sensitive attributes and tasks for which the dataset has been used in the algorithmic fairness literature.
 fairness research

""Data briefs are meant as short documentation providing essential information on datasets
used in fairness research. ""

""We envision several benefits for the algorithmic
equity and data studies research communities""

the algorithmic fairness community

",No,Manual,No,datasheet
Using Large Language Models to Enrich the Documentation of Datasets for Machine Learning,"Giner-Miguelez, Joan; Gómez, Abel; Cabot, Jordi",2024,No,,,dataset practitioners,No,No,"the machine learning community
the description of machine learning datasets",Yes,Automated,No,
Distinguishing provenance equivalence of earth science data,Tilmes,2011,No,"I am not sure this study should be part of the papers we are analyzing. This paper leverages an aspect of dataset documentation (provenance) for the purpose of determining dataset scientific equivalence. It thus, can tell us something about the utility of provenance but no aspect of how provenance is documented is ever touched on. ",,dataset creators,No,No,"Scientific contexts such as earth science, where there is a need to recognize scientifically equivalent datasets",No,Automated,No,
Artsheets for Art Datasets,"Srinivasan, Ramya; Denton, Emily; Famularo, Jordan; Rostamzadeh, Negar; Diaz, Fernando; Coleman, Beth",2021,No,,,"dataset creators, dataset users, dataset users",No,No,ML but also cultural stakeholders,No,Manual,No,datasheet
Healthsheet: Development of a Transparency Artifact for Health Datasets,"Rostamzadeh, Negar; Mincu, Diana; Roy, Subhrajit; Smart, Andrew; Wilcox, Lauren; Pushkarna, Mahima; Schrouff, Jessica; Amironesei, Razvan; Moorosi, Nyalleng; Heller, Katherine",2022,Yes,"Systematic lit review, interviews,  validatio of datasets, and qualitative engagements. (Section 2)",,"dataset creators, data experts, data practitioners",No,Yes,,Yes,Manual,No,questionnaire
A Methodology for Creating AI FactSheets,"Richards, John; Piorkowski, David; Hind, Michael; Houde, Stephanie; Mojsilović, Aleksandra",2020,No,This paper describes a methodology,,"dataset creators, data curators",No,No,The authors propose using their methodology in different context related to developing ai technologies,No,Hybrid,Yes,framework
A Field Study of a Human-Centered Process for Increasing AI Transparency,"Piorkowski, David; Richards, John; Hind, Michael",2024,Yes,Field study and interview study,,dataset creators,No,Yes,The context in which the authors conducted the study was an AI organization in the healthcare domain,Yes,Manual,Yes,app
Reusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards,"McMillan-Major, Angelina; Osei, Salomey; Rodriguez, Juan Diego; Ammanamanchi, Pawan Sasanka; Gehrmann, Sebastian; Jernite, Yacine",2021,No,"The authors conducted a stakeholder analysis. However, the authors did not explicitly mention conducting a formal needs assessment or user research study as a basis for the development of the documentation templates. Instead, the development process involved identifying relevant stakeholder groups (such as dataset curators, model developers, organizations managing the resources, and users), defining guiding principles based on these stakeholders' values, and iteratively revising the templates based on feedback from the community and experts familiar with documentation practices. They also drew on existing documentation templates (e.g., from Bender and Friedman (2018) and Mitchell et al. (2019)) as foundations and adapted them for their specific contexts (HuggingFace and GEM). While there was consideration of stakeholder needs and iterative feedback, there was no direct mention of a formal needs assessment or user research study as typically understood in user-centered design processes.",,"dataset creators, data organizations",No,No,The templates aim to standardize documentation practices across the NLP community and are integrated into platforms such as the HuggingFace dataset hub and the GEM benchmark for natural language generation (NLG).,No,Manual,No,datasheet
Data cards: Purposeful and transparent dataset documentation for responsible AI,"Pushkarna, Mahima; Zaldivar, Andrew; Kjartansson, Oddur",2022,Yes,"The authors worked with 12 teams within a large technology company over 24 months to create 22 Data Cards for various dataset types in production settings. This collaboration allowed them to observe documentation workflows, collaborative information gathering, and review practices. Additionally, they conducted studies, workshops, and surveys involving stakeholders across different roles and expertise levels to identify opportunities, challenges, and information needs in dataset documentation.",,"dataset creators, dataset users",No,Yes,Industry,Yes,Hybrid,Yes,framework
"Can machines help us answering question 16 in datasheets, and in turn reflecting on inappropriate content?","Schramowski, Patrick; Tauchmann, Christopher; Kersting, Kristian",2022,No,,,"dataset creators, data curators",No,No,"The tool, called Q16, is presented by the authors as a semi-automatic method to assist dataset creators in documenting inappropriate image content in large-scale computer vision datasets. Its precise context of use is to help answer Question 16 in Datasheets for Datasets, which asks whether a dataset contains data that might be offensive, insulting, threatening, or otherwise cause anxiety if viewed directly",No,Hybrid,No,app
Augmented datasheets for speech datasets and ethical decision-making,"Papakyriakopoulos, Orestis; Choi, Anna Seo Gyeong; Thong, William; Zhao, Dora; Andrews, Jerone; Bourke, Rebecca; Xiang, Alice; Koenecke, Allison",2023,No,"The authors conducted  a ""literature review on a set of 178 speech studies related to fairness and diversity as well as 220 speech datasets""",,dataset creators,No,No,Datasets in the context of Speech Language Technologies (SLT),No,Manual,No,datasheet
Data statements: From technical concept to community practice,"McMillan-Major, Angelina; Bender, Emily M.; Friedman, Batya",2024,Yes,The authors conducted a NLP Community-BasedWorkshop and then an Analytical Comparison to Datasheets for Datasets,,dataset creators,No,Yes,"There is not an specific context, instead the authors situate their research on the NLP community",No,Manual,No,questionnaire
Clear and precise specification of ecological data management processes and dataset provenance,"Osterweil, Leon J.; Clarke, Lori A.; Ellison, Aaron M.; Boose, Emery; Podorozhny, Rodion; Wise, Alexander",2010,No,,,"dataset creators, data curators",No,No,The use case presented is the Water Budget process at the Harvard Forest Long-Term Ecological Research site.,Yes,Hybrid,No,markup format
Datasheets for Healthcare AI: A Framework for Transparency and Bias Mitigation,"Siddik, Marjia; Pandit, Harshvardhan J.",2025,No,,,"dataset creators, data experts",No,No,"Healthcare, and more specifically in Ireland. The article includes a section (section 4) that describes the Irish Healthcare Context.",No,Automated,No,app
"On Responsible Machine Learning Datasets with Fairness, Privacy, and Regulatory Norms","Mittal, Surbhi; Thakral, Kartik; Singh, Richa; Vatsa, Mayank; Glaser, Tamar; Ferrer, Cristian Canton; Hassner, Tal",2024,No,,,"dataset creators, data experts",No,No,Biometric and healthcare datasets in the context of developing AI technologies.,No,Hybrid,No,framework
Right the docs: Characterising voice dataset documentation practices used in machine learning,"Reid, Kathy; Williams, Elizabeth T.",2023,Yes,Semi-structured interviews,,dataset creators,No,Yes,The context is dataset documentation for voice dataset documents (VDD) in the Machine Learning lifecycle.  Automatic Speech recognition and ML practitioners,No,Hybrid,No,
Completeness of Datasets Documentation on ML/AI Repositories: An Empirical Investigation,"Rondina, Marco; Vetrò, Antonio; De Martin, Juan Carlos",2023,No,,,"dataset creators, data curators",No,No,Dataset documentation in popular ML/AI repositories.,No,Manual,No,markup format
Open Datasheets: Machine-readable Documentation for Open Datasets and Responsible AI Assessments,"Roman, Anthony Cintron; Vaughan, Jennifer Wortman; See, Valerie; Ballard, Steph; Torres, Jehu; Robinson, Caleb; Ferres, Juan M. Lavista",2024,Yes,"The  authors follow a ""multistage process that incorporated feedback from various dataset producers"". In terms of studies/methods, the authors conducted a i)case study analysis, ii) gather qualitative feedback, and iii) conducted a usability testing (see page 3).",,dataset creators,No,Yes,Open datasets for AI applications. ,No,Hybrid,No,framework
Ontology-Supported AI Model and Dataset Management,"Novacek, Jan; Ahari, Ali; Müller, Tobias; Reiter, Sebastian; Viehl, Alexander; Bringmann, Oliver",2024,No,,,"dataset creators, dataset users",No,Yes,"The tool is designed to support interdisciplinary cooperation along the AI model lifecycle, from data acquisition and model development through to end-user deployment, especially in industrial contexts.",Yes,Hybrid,No,app
Ensuring Dataset Quality for Machine Learning Certification,"Picard, S.; Chapdelaine, C.; Cappi, C.; Gardes, L.; Jenn, E.; Lefevre, B.; Soumarmon, T.",2020,No,,,"dataset creators, dataset users",Yes,No,Dataset quality in the context of the development of a ML-based certified system,No,Hybrid,No,questionnaire
dataMaid: Your Assistant for Documenting Supervised Data Quality Screening in R,"Petersen, Anne Helby; Ekstrøm, Claus Thorn",2019,No,,,dataset creators,No,No,"The context is data cleaning workflows [Quote] ""the general challenges in data cleaning and documentation faced by statisticians and data analysts, such as the time-consuming nature of the process, the need for human supervision, and the importance of reproducibility""",No,Hybrid,Yes,app
FactSheets: Increasing trust in AI services through supplier's declarations of conformity,"Arnold, M.; Bellamy, R. K. E.; Hind, M.; Houde, S.; Mehta, S.; Mojsilović, A.; Nair, R.; Ramamurthy, K. Natesan; Olteanu, A.; Piorkowski, D.; Reimer, D.; Richards, J.; Tsay, J.; Varshney, K. R.",2019,No,,,dataset creators,Yes,No,"A marketplace where AI suppliers need a trust, transparency mechanisms for their products to be trusted",No,Manual,No,questionnaire
The Dataset Nutrition Label (2nd Gen): Leveraging Context to Mitigate Harms in Artificial Intelligence,"Chmielinski, Kasia S.; Newman, Sarah; Taylor, Matt; Joseph, Josh; Thomas, Kemi; Yurkofsky, Jessica; Qiu, Yue Chelsea",2022,Yes,This redesign was as a result of interviews and feedback from data scientists and other practitioners,,"dataset creators, data practitioners",Yes,Yes,Research,No,Hybrid,,framework
Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science,"Bender, Emily M.; Friedman, Batya",2018,No,,,dataset creators,No,No,Dataset documentation within NLP,No,Manual,No,questionnaire
Aether Data Documentation Template,,2022,No,,,"dataset creators, dataset auditors",No,No,Development and release of datasets,No,Manual,No,questionnaire
Interactive Model Cards: A Human-Centered Approach to Model Documentation,"Crisan, Anamaria; Drouhard, Margaret; Vig, Jesse; Rajani, Nazneen",2022,Yes,"""[...]  Our investigation consists of an initial conceptual study with experts in ML, NLP, and AI Ethics, followed by a separate evaluative study with non-expert analysts who use ML models in their work. Using a semi-structured interview format coupled with a think-aloud protocol, ",,,Yes,Yes,Production and consuption of datasets for research purposes,Yes,Manual,No,framework
Method cards for prescriptive machine-learning transparency,"Adkins, David; Alsallakh, Bilal; Cheema, Adeel; Kokhlikyan, Narine; McReynolds, Emily; Mishra, Pushkar; Procope, Chavez; Sawruk, Jeremy; Wang, Erin; Zvyagina, Polina",2022,No,,,dataset creators,No,No,Dataset documentation during the ML pipeline,No,Manual,No,framework
The CLeAR Documentation Framework for AI Transparency: Recommendations for Practitioners & Context for Policymakers,,2024,No,,,dataset practitioners,Yes,No,"""This framework aims to provide practi- tioners and policymakers with concrete principles to guide the implementation of Comparable, Legible, Actionable, and Robust documentation of datasets, models, and AI systems. """,No,Manual,No,framework
Machine learning data practices through a data curation lens: An evaluation framework,"Bhardwaj, Eshta; Gujral, Harshit; Wu, Siyi; Zogheib, Ciara; Maharaj, Tegan; Becker, Christoph",2024,Yes,"""mixed-methods analysis of evaluation results for 25 ML datasets, we study the feasibility of data curation principles to be adopted for machine learning data work in practice and explore how data curation is currently performed. """,,dataset practitioners,Yes,No,ML dataset development,Yes,Manual,No,framework
Datasheets for datasets help ML engineers notice and understand ethical issues in training data,"Boyd, Karen L.",2021,Yes,"""think-aloud protocol""",,dataset creators,Yes,Yes,ML dataset development,Yes,Manual,No,
Network report: a structured description for network datasets,"Zheng, Xinyi; Rossi, Ryan A.; Ahmed, Nesreen K.; Moritz, Dominik",2022,No,,,"dataset creators, dataset users",Yes,No,Development of network datasets,Yes,Hybrid,No,datasheet
On the effectiveness of dataset watermarking,"Atli Tekgul, Buse Gul; Asokan, N.",2022,No,,,dataset creators,No,No,Provenance and verification of datasets,Yes,Automated,Yes,app
Datasheet for subjective and objective quality assessment datasets,"Barman, Nabajeet; Reznik, Yuriy; Martini, Maria",2023,No,,,"dataset creators, dataset users",No,No,"""The datasheet can be filled by either the dataset creator or the end-user and then shared for easier understanding and reproducibility of their work.",Yes,Manual,No,datasheet
Prov-Dominoes: An approach for knowledge discovery from provenance data,"Alencar, Victor; Kohwalter, Troy; Braganholo, Vanessa; da Silva, José Ricardo; Murta, Leonardo",2024,No,,,dataset creators,No,No,"""Prov-Dominoes promotes the provenance relationships among entities, activities, and agents into first-class elements represented by domino tiles. It allows users to combine and compose such domino tiles visually and interactively, using GPU.""",No,Hybrid,Yes,app
Tackling algorithmic bias and promoting transparency in health datasets: the STANDING Together consensus recommendations,"Alderman, Joseph E; Palmer, Joanne; Laws, Elinor; McCradden, Melissa D; Ordish, Johan; Ghassemi, Marzyeh; Pfohl, Stephen R; Rostamzadeh, Negar; Cole-Lewis, Heather; Glocker, Ben; Calvert, Melanie; Pollard, Tom J; Gill, Jaspret; Gath, Jacqui; Adebajo, Adewale; Beng, Jude; Leung, Cassandra H; Kuku, Stephanie; Farmer, Lesley-Anne; Matin, Rubeta N; Mateen, Bilal A; McKay, Francis; Heller, Katherine; Karthikesalingam, Alan; Treanor, Darren; Mackintosh, Maxine; Oakden-Rayner, Lauren; Pearson, Russell; Manrai, Arjun K; Myles, Puja; Kumuthini, Judit; Kapacee, Zoher; Sebire, Neil J; Nazer, Lama H; Seah, Jarrel; Akbari, Ashley; Berman, Lew; Gichoya, Judy W; Righetto, Lorenzo; Samuel, Diana; Wasswa, William; Charalambides, Maria; Arora, Anmol; Pujari, Sameer; Summers, Charlotte; Sapey, Elizabeth; Wilkinson, Sharon; Thakker, Vishal; Denniston, Alastair; Liu, Xiaoxuan",2025,Yes,"""mixed-methods research programme"" including literature review and delphi project (consultation with panel of experts)",,"dataset creators, data experts. dataset researchers",Yes,Yes,"""These recommendations have a specific focus on datasets used for the development, evaluation, and monitoring of AI health technologies, and respond to increasing international awareness of algorithmic bias and the wider harms of under-representative, biased datasets""",No,Manual,No,questionnaire
Toward FAIR Semantic Publishing of Research Dataset Metadata in the Open Research Knowledge Graph,"Ahmad, Raia Abu; D'Souza, Jennifer; Zloch, Matthäus; Otto, Wolfgang; Rehm, Georg; Oelen, Allard; Dietze, Stefan; Auer, Sören",2024,No,,,dataset researchers,No,No,Data researchers will type all documents when uploading datasets to repositories,No,Hybrid,Yes,markup format
Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on Hugging Face,"Yang, Xinyu; Liang, Weixin; Zou, James",2024,No,,,,No,No,,,,,
The State of Data Curation at NeurIPS: An Assessment of Dataset Development Practices in the Datasets and Benchmarks Track,"Bhardwaj, Eshta; Gujral, Harshit; Wu, Siyi; Zogheib, Ciara; Maharaj, Tegan; Becker, Christoph",2025,No,,,data curators,Yes,No,,,,,
Data Readiness Report,"Afzal, Shazia; Rajmohan, C; Kesarwani, Manish; Mehta, Sameep; Patel, Hima",2021,No,,,"dataset practitioners, dataset creators",No,No,"""documentation of operations conducted during the data prepa- ration, cleaning, and quality analysis phases in a typical AI life cycle.""",No,Manual,No,questionnaire
MithraLabel: Flexible Dataset Nutritional Labels for Responsible Data Science,"Sun, Chenkai; Asudeh, Abolfazl; Jagadish, H. V.; Howe, Bill; Stoyanovich, Julia",2019,No,,,dataset creators,No,No,"""Our system is implemented as a web application. Clients use the Front-end to identify a dataset, a task, and the label details. The request will then be passed to the back-end where the nutritional label is constructed.""",No,Automated,Yes,app
How to Automatically Document Data With the codebook Package to Facilitate Data Reuse,"Arslan, Ruben C.",2019,No,,,dataset creators,No,No,"""The codebook package gives psychological scientists a tool they can use in the short term, and that potentially even saves them time, in order to create a resource that is useful for everyone in the long term. It automates commonly performed data-summary steps, such as gen- erating descriptive statistics and plots""",No,Automated,No,app
The ABC of Data: A Classifying Framework for Data Readiness,"Castelijns, Laurens A.; Maas, Yuri; Vanschoren, Joaquin",2020,No,,,dataset creators,No,No,Automate and document the data cleaning process,No,Automated,Yes,framework
Croissant: A Metadata Format for ML-Ready Datasets,"Akhtar, Mubashara; Benjelloun, Omar; Conforti, Costanza; Gijsbers, Pieter; Giner-Miguelez, Joan; Jain, Nitisha; Kuchnik, Michael; Lhoest, Quentin; Marcenac, Pierre; Maskey, Manil; Mattson, Peter; Oala, Luis; Ruyssen, Pierre; Shinde, Rajat; Simperl, Elena; Thomas, Goeffry; Tykhonov, Slava; Vanschoren, Joaquin; van der Velde, Jos; Vogler, Steffen; Wu, Carole-Jean",2024,No,,,dataset practitioners,No,No,"Describe most types of data commonly used in ML workflows, such as images, text, or audio",No,Automated,Yes,markup format